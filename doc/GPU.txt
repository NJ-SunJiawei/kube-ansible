# 查看显卡信息（若找不到lspci命令，可以安装 yum install pciutils）
lspci | grep -i nvidia

# 查看内核版本
uname -r

# 查看可以安装的kernel-devel版本
yum list | grep kernel-devel

# 安装kernel-devel（安装的版本要和当前内核版本一致）
yum install -y kernel-devel-$(uname -r) kernel-headers-$(uname -r)

# 安装gcc dkms
yum -y install gcc dkms

# 查看nouveau加载情况
lsmod | grep nouveau

# 阻止 nouveau 模块加载 //openEuler系统在/usr/lib/modprobe.d/dist-blacklist.conf目录
cat >  /etc/modprobe.d/blacklist.conf << EOF
blacklist nouveau
options nouveau modeset=0
EOF

# 重新建立initramfs image文件（此步骤操作完成之后，需重启机器）
mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak
dracut /boot/initramfs-$(uname -r).img $(uname -r)

# 安装驱动
bash NVIDIA-Linux-x86_64-470.199.02.run

# 验证驱动是否安装成功
nvidia-smi

# 添加nvidia-container-toolkit软件源
# 企业内部建议使用nexus配置nvidia-container-toolkit软件源的代理，并将group_vars/all.yml中repo修改为nexus代理地址，即可实现自动安装
# 其他操作系统请参考: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#linux-distributions
#cat  >  /etc/yum.repos.d/nvidia-container-toolkit.repo  << EOF
#[nvidia-container-toolkit]
#name=nvidia-container-toolkit
#baseurl=https://nvidia.github.io/libnvidia-container/stable/rpm/\$basearch
#repo_gpgcheck=1
#gpgcheck=0
#enabled=1
#gpgkey=https://nvidia.github.io/libnvidia-container/gpgkey
#sslverify=1
#sslcacert=/etc/pki/tls/certs/ca-bundle.crt
#EOF

#或者：
#ARM架构下安装nvidia-container-toolkit （centos7不支持aarch64的）
#curl -s -L https://nvidia.github.io/nvidia-docker/centos8/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo
#sudo yum install -y nvidia-container-toolkit

# 安装nvidia-container-toolkit
#yum -y install nvidia-container-runtime(2023年后废弃了) nvidia-container-toolkit

github下载：
https://github.com/NVIDIA/nvidia-container-toolkit/releases


官方参考：
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-containerd-for-kubernetes
https://docs.nvidia.com/datacenter/cloud-native/#kubernetes-and-nvidia-gpus
下面这个管用，官方有问题
https://zhangguanzhang.github.io/2024/04/08/nvidia-container-toolkit/#/%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AE
rpm repo（参考）
https://github.com/NVIDIA/libnvidia-container/tree/gh-pages

虚拟化：
NVIDIA GPU虚拟化主要有以下几种方法：

| 方法                  | 描述                                                                                                   | 优点                                                                                               | 适用场景                                      |
|-----------------------|--------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|-----------------------------------------------|
| **vGPU (Virtual GPU)**| 利用NVIDIA vGPU软件将物理GPU划分为多个虚拟GPU，使多个虚拟机共享一块物理GPU。                            | 高效利用GPU资源，支持多种工作负载，灵活分配。                                                      | 桌面虚拟化、工作站虚拟化、云计算              |
| **CUDA Multi-Process Service (MPS)** | 允许多个CUDA应用共享同一个GPU，同时运行，提升GPU利用率。                                     | 提高多用户环境下的并行计算能力，减少上下文切换开销。                                                | 高性能计算（HPC）、深度学习训练               |
| **GPU Passthrough**   | 将物理GPU直接分配给虚拟机，虚拟机可以独占使用该GPU。                                                    | 性能接近裸机，适合对GPU性能要求高的应用。                                                          | 高性能计算、图形渲染、游戏服务器              |
| **Docker GPU 支持**   | 通过NVIDIA Docker运行容器化的应用，使容器可以直接访问主机的GPU。                                         | 容器化管理，方便应用部署和迁移，支持多种深度学习框架。                                              | 深度学习、容器化应用                          |
| **Mig (Multi-Instance GPU)** | NVIDIA A100等新型GPU支持将单个GPU划分为多个独立的小实例，每个实例有独立的资源配额和隔离机制。    | 精细的资源分配和隔离，适合多租户环境和并行计算。                                                    | 数据中心、多租户环境、AI推理工作负载          |
| **SR-IOV (Single Root I/O Virtualization)** | 通过硬件支持将物理GPU的资源划分为多个虚拟功能（Virtual Function，VF），每个VF可以独立使用。| 硬件级虚拟化，提供高性能和低延迟的GPU访问。                                                        | 数据中心、云计算                              |

容器和GPU混合部署
https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-kubevirt.html