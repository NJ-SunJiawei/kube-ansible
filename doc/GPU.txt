# 查看显卡信息（若找不到lspci命令，可以安装 yum install pciutils）
lspci | grep -i nvidia

# 查看内核版本
uname -r

# 查看可以安装的kernel-devel版本
yum list | grep kernel-devel

# 安装kernel-devel（安装的版本要和当前内核版本一致）
yum install -y kernel-devel-$(uname -r) kernel-headers-$(uname -r)

# 安装gcc dkms
yum -y install gcc dkms

# 查看nouveau加载情况
lsmod | grep nouveau

# 阻止 nouveau 模块加载 //openEuler系统在/usr/lib/modprobe.d/dist-blacklist.conf目录
cat >  /etc/modprobe.d/blacklist.conf << EOF
blacklist nouveau
options nouveau modeset=0
EOF

# 重新建立initramfs image文件（此步骤操作完成之后，需重启机器）
mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak
dracut /boot/initramfs-$(uname -r).img $(uname -r)

# 安装驱动
bash NVIDIA-Linux-x86_64-470.199.02.run

# 验证驱动是否安装成功
nvidia-smi

# 添加nvidia-container-toolkit软件源
# 企业内部建议使用nexus配置nvidia-container-toolkit软件源的代理，并将group_vars/all.yml中repo修改为nexus代理地址，即可实现自动安装
# 其他操作系统请参考: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#linux-distributions
#cat  >  /etc/yum.repos.d/nvidia-container-toolkit.repo  << EOF
#[nvidia-container-toolkit]
#name=nvidia-container-toolkit
#baseurl=https://nvidia.github.io/libnvidia-container/stable/rpm/\$basearch
#repo_gpgcheck=1
#gpgcheck=0
#enabled=1
#gpgkey=https://nvidia.github.io/libnvidia-container/gpgkey
#sslverify=1
#sslcacert=/etc/pki/tls/certs/ca-bundle.crt
#EOF

#或者：
#ARM架构下安装nvidia-container-toolkit （centos7不支持aarch64的）
#curl -s -L https://nvidia.github.io/nvidia-docker/centos8/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo
#sudo yum install -y nvidia-container-toolkit

# 安装nvidia-container-toolkit
#yum -y install nvidia-container-runtime(2023年后废弃了) nvidia-container-toolkit

github下载：
https://github.com/NVIDIA/nvidia-container-toolkit/releases


官方参考：
https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-containerd-for-kubernetes
https://docs.nvidia.com/datacenter/cloud-native/#kubernetes-and-nvidia-gpus
下面这个管用，官方有问题
https://zhangguanzhang.github.io/2024/04/08/nvidia-container-toolkit/#/%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AE
rpm repo（参考）
https://github.com/NVIDIA/libnvidia-container/tree/gh-pages

虚拟化：
NVIDIA GPU虚拟化主要有以下几种方法：

在大类上计算虚拟化技术有这3种： 软件模拟、直通独占(如网卡独占、显卡独占)、直通共享（如vCPU 、vGPU）。但对于显卡GPU而言我总结细化出至少这6种分类(其中第四、五种都是第三种的具体实现)：

第一种、软件模拟（eg sGPU）, 又叫半虚拟化。
第二种、直通独占 (pGPU) , 有的文章翻译为透传 。Openstack/KVM/ESX等IaaS场景用到。
第三种、直通共享 (基于SR-IOV技术虚拟出vGPU) , 在技术上分类叫全虚拟化 。三个大厂有部分型号GPU支持，具体型号见 https://open-iov.org/index.php/GPU_Support 。这是AMD首先搞出来的，但似乎他们后来也转向GPU分片虚拟化了，这个网站AMD的产品反而没几款。
第四种、GPU分片虚拟化（mediated passthrough），也属于全虚拟化技术。其热度很高，基于VFIO mediated passthrough framework的GPU虚拟化方案。该方案由NVIDIA提出，并联合Intel一起提交到了Linux kernel 4.10代码库，该方案的kernel部分代码简称mdev模块。把会影响性能的访问直接passthrough给虚拟机，把性能无关，功能性的MMIO访问做拦截并在mdev模块内做模拟。商业产品有NVIDIA GRID vGPU 与Intel的GVT-g系列，前者不开源，后者大部分开源。
第五种、多实例 GPU (MIG) 技术，也属于全虚拟化技术。MIGNvidia 搞出的新技术，可将单个 GPU 分区为最多 7个完全的隔离vGPU实例，减少资源争抢的延时，提高物理 GPU 利用率。但可惜目前仅昂贵和国内禁售的NVIDIA A100 GPU 支持。
第六种。Time-Slicing GPU （时间共享GPU）。把本来再空间上并行（时间独占）的成百上千的GPU流水线进行的时间维度的分割和共享。各个GPU厂家都有类似的技术。英伟达的技术文档：https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html 。
注意，以上第四种是收费的，所以企业用户要去英伟达官网购买license。英伟达又卖硬件又卖软件license,赚钱能力真强。
第五种MIG则是买到昂贵的A100卡就能用了，不需要license。
普通玩k8s的企业，则用免费的Time-Slicing GPU (时间分片共享GPU) 。
————————————————

容器和GPU混合部署
https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-kubevirt.html