# 安装目录 
software_dir: '/data/k8s_install/k8s_1.24.2'
k8s_work_dir: '/opt/kubernetes'
k8s_addons_dir: '{{ k8s_work_dir }}/addons'
etcd_work_dir: '/opt/etcd'
tmp_dir: '/tmp/k8s'

#cfssl工具:arm/x86
cfssl_type: 'arm'

# 集群网络
service_cidr: '10.0.0.0/24'
cluster_dns: '10.0.0.2'   # 与roles/addons/files/coredns.yaml中IP一致，并且是service_cidr中的IP
pod_cidr: '10.244.0.0/16' # 与calico/flannel中网段一致
service_nodeport_range: '30000-32767'
cluster_domain: 'cluster.local'

# 高可用，如果部署单Master，该项忽略
vip: '192.168.114.88'
nic: 'ens33'  # 修改为实际内网网卡名

# 自签证书可信任IP列表，为方便扩展，可添加多个预留IP
cert_hosts:
  # 包含所有LB、VIP、Master IP和service_cidr的第一个IP
  k8s:
    - 10.0.0.1
    - 192.168.114.88
    - 192.168.114.30
    - 192.168.114.31
    - 192.168.114.32
    - 192.168.114.33
    - 192.168.114.34
    - 192.168.114.35
    - 192.168.114.36
    - 192.168.114.37
    - 192.168.114.38
    - 192.168.114.39
    - 192.168.114.40
    - 192.168.114.41
    - 192.168.114.42
    - 192.168.114.43
    - 192.168.114.44
    - 192.168.114.45
    - 192.168.114.46
    - 192.168.114.47
    - 192.168.114.48
    - 192.168.114.49
    - 192.168.114.100
    - 192.168.114.101
    - 192.168.114.102
    - 192.168.114.103
    - 192.168.114.104
    - 192.168.114.105
    - 192.168.114.106
    - 192.168.114.107
    - 192.168.114.108
    - 192.168.114.109
    - 192.168.114.110
    - 192.168.114.111
    - 192.168.114.112
    - 192.168.114.113
    - 192.168.114.114
    - 192.168.114.115
    - 192.168.114.116
    - 192.168.114.117
    - 192.168.114.118
    - 192.168.114.119
  # 包含所有etcd节点IP
  etcd:
    - 192.168.114.112
#    - 192.168.114.34
#    - 192.168.114.35

############################
# network
############################
multus_install: "yes"
cluster_network: "calico" #calico/flannel/kube-ovn/
# ------------------------------------------- flannel
# [flannel]设置flannel 后端"host-gw","vxlan"等
flannel_backend: "vxlan"
direct_routing: false #支持vxlan在相同子网情况下数据包直接通过路由转发,与HOST-GW模式相同
# ------------------------------------------- calico
# [calico] IPIP隧道模式可选项有: [Always, CrossSubnet, Never],跨子网可以配置为Always与CrossSubnet(公有云建议使用always比较省事，其他的话需要修改各自公有云的网络配置，具体可以参考各个公有云说明)
# 其次CrossSubnet为隧道+BGP路由混合模式可以提升网络性能，同子网配置为Never即可.
calico_ipv4pool_ipip: "Always"
# [calico]设置 calico-node使用的host IP，bgp邻居通过该地址建立，可手工指定也可以自动发现
ip_autodetection_method: "can-reach={{ groups['master'] }}" #interface=ens.*  cidr=10.20.0.0/24
# [calico]设置calico 网络 backend: bird, vxlan, none
calico_networking_backend: "bird"
# [calico]设置calico 是否使用route reflectors
# 如果集群规模超过50个节点，建议启用该特性
calico_rr_enable: false
# calico_rr_nodes 配置route reflectors的节点，如果未设置默认使用集群master节点 
# calico_rr_nodes: ["192.168.1.1", "192.168.1.2"]
calico_rr_nodes: []
# etcd 集群服务地址列表, 根据etcd组成员自动生成
tmp_endpoints: "{% for h in groups['etcd'] %}https://{{ h }}:2379,{% endfor %}"
etcd_endpoints: "{{ tmp_endpoints.rstrip(',') }}"
# calico AS number
calico_as_number: 64512
############################
# ipvs
############################
proxy_mode: "ipvs" #不填默认为iptables
enable_ipvs_strict_arp: false #false真实服务器只对来自虚拟服务器 IP 的 ARP 请求做出响应
ipvs_scheduler_type: "rr"

############################
# ha高可用(多master)
############################
ha_support: false

############################
# gpu
############################
nvidia_toolkit_ver: "1.16.1"
nvidia_gpu_plugin_ver: "0.16.1"
nvidia_gpu_share_rename: "false"
nvidia_gpu_config_replicas: 10  #mps最大48、time无限制

############################
# nfs server
############################
nfs_default_path: "/data/k8s"

############################
#metrics-server
#和kubesphere二选一
############################
metrics_server_install: "yes"

############################
#dashboard
#和kubesphere二选一
############################
dashboard_install: "no"
dashboard_nodeport: 30001

############################
# prometheus+grafana
# 和kubesphere二选一
############################
prom_install: "no"
prom_namespace: "monitor"
prom_chart_ver: "45.23.0"
prom_operator_nodeport: 30899
prom_operator_nodeport_tls: 30900
prom_self_nodeport: 30901
prom_alertmanager_nodeport: 30902
prom_grafana_nodeport: 30903

############################
# kubesphere 30880
############################
kubesphere_install: "yes"
kubesphere_ver: "3.3.2"
kubesphere_api_nodeport: 30801
kubesphere_nodeport: 30880
kubesphere_password: "P@88w0rd"
#host官方是有bug的，拆分安装
kubesphere_clusterRole_host: "yes"
kubesphere_clusterRole_others: "none" #no:member(从集群) | yes:none(主机群) |no:none(default)
kubesphere_jwtSecret: "" #从集群时候填充
#查询jwtSecret： kubectl -n kubesphere-system get cm kubesphere-config -o yaml | grep -v "apiVersion" | grep jwtSecret
############################
# helm charts
#和kubeconfig部署在一起
############################
HELM_VER: "v3.11.1"
HELM_PATH: "/root/helm"
HELM_PORT: 80 #harbor和helm部署在一起 端口不可为80
HELM_CHARTS: "private" #public为官方联网

############################
# harbor
############################
HARBOR_VER: "v2.10.2"
HARBOR_DOMAIN: "registry.zjy.com"
HARBOR_PATH: "/var/data"
HARBOR_TLS_PORT: 443
#如果端口等于443，HARBOR_REGISTRY可以不需要HARBOR_TLS_PORT
HARBOR_REGISTRY: "{{ HARBOR_DOMAIN }}"
#HARBOR_REGISTRY: "{{ HARBOR_DOMAIN }}:{{ HARBOR_TLS_PORT }}"
HARBOR_PASSWORD: "zjy@123456"
HARBOR_DB_PASSWORD: "zjydb@123456" 
# install extra component
HARBOR_WITH_TRIVY: false

############################
# role:runtime [containerd,docker]
############################
# [.]docker启用拉取加速镜像仓库
ENABLE_MIRROR_REGISTRY: true

# [.]添加信任的私有仓库
# 必须按照如下示例格式，协议头'http://'和'https://'不能省略
INSECURE_REG:
  - "https://harbor.yourcompany.com"
#  - "http://{{ groups['harbor'][0] }}:8080"

# [containerd]容器持久化存储目录
CONTAINERD_STORAGE_DIR: "/var/lib/containerd"

# [docker]容器存储目录
DOCKER_STORAGE_DIR: "/var/lib/docker"

# [docker]开启Restful API
DOCKER_ENABLE_REMOTE_API: false